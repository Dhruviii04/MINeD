{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab\n",
        "!pip install docx2pdf\n",
        "!pip install Pillow\n",
        "!pip install markdown2\n",
        "!pip install weasyprint\n",
        "!pip install python-pptx\n",
        "!pip install PyMuPDF\n",
        "!pip install textract\n",
        "!pip install openpyxl\n",
        "!pip install beautifulsoup4\n",
        "!pip install python-docx\n",
        "!pip install openpyxl\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "veq_jPLdqfQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J_g6zKnqLiE"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import fitz  # PyMuPDF\n",
        "import docx2txt\n",
        "import os\n",
        "import requests\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "# Function to extract text from PDF, DOCX, or TXT files\n",
        "def extract_text_from_file(file_path):\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        with fitz.open(file_path) as doc:\n",
        "            text = \"\"\n",
        "            for page in doc:\n",
        "                text += page.get_text()\n",
        "        return text\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        return docx2txt.process(file_path)\n",
        "    elif file_path.endswith(\".txt\"):\n",
        "        with open(file_path, \"r\") as file:\n",
        "            return file.read()\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# Function to load documents and set up question-answering pipeline\n",
        "def ask_question(question, files):\n",
        "    # Load text from uploaded files\n",
        "    texts = [extract_text_from_file(file.name) for file in files]\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    # content = \"\\n\\n\".join(str(page.page_content) for page in data)\n",
        "\n",
        "    textss = text_splitter.split_text(texts)\n",
        "    # Initialize embeddings and vector store\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    vector_store = Chroma.from_texts(textss, embeddings).as_retriever()\n",
        "\n",
        "    # Set up prompt for question-answering\n",
        "    prompt_template = \"\"\"\n",
        "    Please answer the question in as much detail as possible based on the provided context.\n",
        "    Ensure to include all relevant details. If the answer is not available in the provided context,\n",
        "    kindly respond with \"The answer is not available in the context.\" Please avoid providing incorrect answers.\n",
        "\n",
        "    Context:\\n {context}?\\n\n",
        "    Question: \\n{question}\\n\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "    # Load question-answering model\n",
        "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
        "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "    # Get relevant documents for the question\n",
        "    docs = vector_store.get_relevant_documents(question)\n",
        "\n",
        "    # Get response from question-answering model\n",
        "    response = chain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Interface setup\n",
        "html = \"\"\"\n",
        "<div style=\"text-align:center; max-width: 700px;\">\n",
        "    <h1>ChatDocuments</h1>\n",
        "    <p> Upload Documents (PDF, DOCX, or TXT), then click on Load Documents <br>\n",
        "    Once the documents have been loaded you can begin chatting with them =)\n",
        "</div>\"\"\"\n",
        "css = \"\"\"container{max-width:700px; margin-left:auto; margin-right:auto; padding:20px}\"\"\"\n",
        "with gr.Blocks(css=css, theme=gr.themes.Monochrome()) as demo:\n",
        "    gr.HTML(html)\n",
        "    with gr.Column():\n",
        "        gr.Markdown('ChatDocuments')\n",
        "        file_upload = gr.Files(label=\"Upload documents\", file_types=['.pdf', '.docx', '.txt'])\n",
        "        input_text = gr.Textbox(label=\"Type in your question\")\n",
        "        output_text = gr.Textbox(label=\"Answer\")\n",
        "        submit_query_button = gr.Button(\"Submit query\")\n",
        "\n",
        "        submit_query_button.click(ask_question, inputs=[input_text, file_upload], outputs=output_text)\n",
        "\n",
        "demo.launch()"
      ]
    }
  ]
}